{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgIxAICJ86yqTEocAM97L/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saim-Hassan786/Tracing-With-OpenAI-Agents-SDK/blob/main/Tracing_With_OpenAI_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai-agents"
      ],
      "metadata": {
        "id": "roGrbNl95RCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4208a6d-ac96-41d0-b943-b09856a8af87"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/120.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.1/125.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m717.5/717.5 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "zpJTe_1dXAk0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "UWqVawAoXP9Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent,Runner,set_default_openai_api,set_default_openai_client\n",
        "from openai import AsyncOpenAI\n",
        "\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=GOOGLE_API_KEY,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "set_default_openai_client(external_client)\n",
        "set_default_openai_api(\"chat_completions\")"
      ],
      "metadata": {
        "id": "YN-HFFOSW5RS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Code Below Is For Tracing With OpenAI API Key And Their Tracing Platform"
      ],
      "metadata": {
        "id": "CXmvSszMazJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import trace\n",
        "async def main():\n",
        "   agent = Agent(\n",
        "    name = \"Joke Teller Agent\",\n",
        "    instructions=\"Tell a joke to the user\",\n",
        "    model = \"gemini-2.0-flash\"\n",
        ")\n",
        "\n",
        "   with trace(\"Joker Tracing\"):\n",
        "    result_1 = await Runner.run(agent, \"Tell me a joke\")\n",
        "    result_2 = await Runner.run(agent, f\"Rate this joke out of 10 {result_1.final_output}\")\n",
        "    print(result_1.final_output)\n",
        "    print(result_2.final_output)"
      ],
      "metadata": {
        "id": "QD2F9mk7X0eF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl3qmt6LYbaR",
        "outputId": "48958419-4b38-4564-ac4b-581990da944b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why don't scientists trust atoms? \n",
            "\n",
            "Because they make up everything!\n",
            "\n",
            "Okay, I'd rate that joke a **7/10**.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "*   **It's a classic:** The pun is well-known and relies on the double meaning of \"make up.\" It's a reliable, crowd-pleasing joke.\n",
            "*   **Simple and easy to understand:** The joke doesn't require a lot of background knowledge or complex thinking. Anyone who has a basic understanding of science and language can get it.\n",
            "*   **Pun-based humor:** Puns are often enjoyable, as they create a humorous twist on words.\n",
            "*   **Slightly overused:** Because it's so well-known, some people might have heard it many times before, which reduces its impact.\n",
            "*   **Clean and inoffensive:** Suitable for all audiences\n",
            "\n",
            "Overall, it's a good, solid joke that's likely to get at least a chuckle.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All The Above Generated tracings Can be Viewed And Traced Through OpenAI Platform"
      ],
      "metadata": {
        "id": "6gnYFyM8bNng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now To View racing Locally Also Called As Local Tracing"
      ],
      "metadata": {
        "id": "2cmy70OuelUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import (\n",
        "    Agent,\n",
        "    Runner,\n",
        "    set_default_openai_client,\n",
        "    set_default_openai_api,\n",
        "    set_trace_processors\n",
        ")\n",
        "\n",
        "from pprint import pprint\n",
        "from openai import AsyncOpenAI\n",
        "from agents.tracing.processor_interface import TracingProcessor\n",
        "\n",
        "class LocalTracing(TracingProcessor):\n",
        "  def __init__(self):\n",
        "    self.traces = []\n",
        "    self.spans = []\n",
        "\n",
        "  def on_trace_start(self, trace):\n",
        "    self.traces.append(trace)\n",
        "    print(f\"Trace Started: {trace.trace_id}\")\n",
        "\n",
        "  def on_trace_end(self, trace):\n",
        "    print(f\"Trace Ended :{trace.export()}\")\n",
        "\n",
        "  def on_span_start(self, span):\n",
        "    self.spans.append(span)\n",
        "    print(f\"Span Started: {span.span_id}\")\n",
        "    print(\"Spane Details:\")\n",
        "    pprint(span.export())\n",
        "\n",
        "  def on_span_end(self, span):\n",
        "    print(f\"Span Ended: {span.span_id}\")\n",
        "    print(\"Spane Details:\")\n",
        "    pprint(span.export())\n",
        "\n",
        "  def force_flush(self):\n",
        "    print(\"Flushing traces and spans\")\n",
        "\n",
        "  def shutdown(self):\n",
        "    print(\"=======Shuting Down========\")\n",
        "    print(\"Collected Traces\")\n",
        "    for trace in self.traces:\n",
        "      print(trace.export())\n",
        "    print(\"Collected Spans\")\n",
        "    for span in self.spans:\n",
        "      print(span.export())\n",
        "\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=GOOGLE_API_KEY,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "set_default_openai_client(\n",
        "    client=external_client,\n",
        "    use_for_tracing=True\n",
        ")\n",
        "\n",
        "set_default_openai_api(\"chat_completions\")\n",
        "\n",
        "local_tracing = LocalTracing()\n",
        "set_trace_processors([local_tracing])\n",
        "\n",
        "\n",
        "from agents import trace\n",
        "async def main_1():\n",
        "   agent = Agent(\n",
        "    name = \"Joke Teller Agent\",\n",
        "    instructions=\"Tell a joke to the user\",\n",
        "    model = \"gemini-2.0-flash\"\n",
        ")\n",
        "\n",
        "   with trace(\"Joker Tracing\"):\n",
        "    result_1 = await Runner.run(agent, \"Tell me a joke\")\n",
        "    result_2 = await Runner.run(agent, f\"Rate this joke out of 10 {result_1.final_output}\")\n",
        "    print(result_1.final_output)\n",
        "    print(result_2.final_output)"
      ],
      "metadata": {
        "id": "tWGeAx7rawLB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asyncio.run(main_1())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Utzz7vuIj7r3",
        "outputId": "3b6117f3-d953-4aae-f3de-0d51a2e0007a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trace Started: trace_04d70b6ce85b477ea557338afc31422b\n",
            "Span Started: span_04c589b47f0c4eb19034c117\n",
            "Spane Details:\n",
            "{'ended_at': None,\n",
            " 'error': None,\n",
            " 'id': 'span_04c589b47f0c4eb19034c117',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': None,\n",
            " 'span_data': {'handoffs': [],\n",
            "               'name': 'Joke Teller Agent',\n",
            "               'output_type': 'str',\n",
            "               'tools': None,\n",
            "               'type': 'agent'},\n",
            " 'started_at': '2025-05-22T15:20:05.546980+00:00',\n",
            " 'trace_id': 'trace_04d70b6ce85b477ea557338afc31422b'}\n",
            "Span Started: span_dcedfd3ad8f249d5bb93e5bf\n",
            "Spane Details:\n",
            "{'ended_at': None,\n",
            " 'error': None,\n",
            " 'id': 'span_dcedfd3ad8f249d5bb93e5bf',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': 'span_04c589b47f0c4eb19034c117',\n",
            " 'span_data': {'input': None,\n",
            "               'model': 'gemini-2.0-flash',\n",
            "               'model_config': {'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/',\n",
            "                                'extra_body': None,\n",
            "                                'extra_headers': None,\n",
            "                                'extra_query': None,\n",
            "                                'frequency_penalty': None,\n",
            "                                'include_usage': None,\n",
            "                                'max_tokens': None,\n",
            "                                'metadata': None,\n",
            "                                'parallel_tool_calls': None,\n",
            "                                'presence_penalty': None,\n",
            "                                'reasoning': None,\n",
            "                                'store': None,\n",
            "                                'temperature': None,\n",
            "                                'tool_choice': None,\n",
            "                                'top_p': None,\n",
            "                                'truncation': None},\n",
            "               'output': None,\n",
            "               'type': 'generation',\n",
            "               'usage': None},\n",
            " 'started_at': '2025-05-22T15:20:05.547994+00:00',\n",
            " 'trace_id': 'trace_04d70b6ce85b477ea557338afc31422b'}\n",
            "Span Ended: span_dcedfd3ad8f249d5bb93e5bf\n",
            "Spane Details:\n",
            "{'ended_at': '2025-05-22T15:20:06.845355+00:00',\n",
            " 'error': None,\n",
            " 'id': 'span_dcedfd3ad8f249d5bb93e5bf',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': 'span_04c589b47f0c4eb19034c117',\n",
            " 'span_data': {'input': [{'content': 'Tell a joke to the user',\n",
            "                          'role': 'system'},\n",
            "                         {'content': 'Tell me a joke', 'role': 'user'}],\n",
            "               'model': 'gemini-2.0-flash',\n",
            "               'model_config': {'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/',\n",
            "                                'extra_body': None,\n",
            "                                'extra_headers': None,\n",
            "                                'extra_query': None,\n",
            "                                'frequency_penalty': None,\n",
            "                                'include_usage': None,\n",
            "                                'max_tokens': None,\n",
            "                                'metadata': None,\n",
            "                                'parallel_tool_calls': None,\n",
            "                                'presence_penalty': None,\n",
            "                                'reasoning': None,\n",
            "                                'store': None,\n",
            "                                'temperature': None,\n",
            "                                'tool_choice': None,\n",
            "                                'top_p': None,\n",
            "                                'truncation': None},\n",
            "               'output': [{'annotations': None,\n",
            "                           'audio': None,\n",
            "                           'content': \"Why don't scientists trust atoms?\\n\"\n",
            "                                      '\\n'\n",
            "                                      'Because they make up everything!\\n',\n",
            "                           'function_call': None,\n",
            "                           'refusal': None,\n",
            "                           'role': 'assistant',\n",
            "                           'tool_calls': None}],\n",
            "               'type': 'generation',\n",
            "               'usage': {'input_tokens': 10, 'output_tokens': 16}},\n",
            " 'started_at': '2025-05-22T15:20:05.547994+00:00',\n",
            " 'trace_id': 'trace_04d70b6ce85b477ea557338afc31422b'}\n",
            "Span Ended: span_04c589b47f0c4eb19034c117\n",
            "Spane Details:\n",
            "{'ended_at': '2025-05-22T15:20:06.846928+00:00',\n",
            " 'error': None,\n",
            " 'id': 'span_04c589b47f0c4eb19034c117',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': None,\n",
            " 'span_data': {'handoffs': [],\n",
            "               'name': 'Joke Teller Agent',\n",
            "               'output_type': 'str',\n",
            "               'tools': [],\n",
            "               'type': 'agent'},\n",
            " 'started_at': '2025-05-22T15:20:05.546980+00:00',\n",
            " 'trace_id': 'trace_04d70b6ce85b477ea557338afc31422b'}\n",
            "Span Started: span_6f46daf9fb5a4433b51b336b\n",
            "Spane Details:\n",
            "{'ended_at': None,\n",
            " 'error': None,\n",
            " 'id': 'span_6f46daf9fb5a4433b51b336b',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': None,\n",
            " 'span_data': {'handoffs': [],\n",
            "               'name': 'Joke Teller Agent',\n",
            "               'output_type': 'str',\n",
            "               'tools': None,\n",
            "               'type': 'agent'},\n",
            " 'started_at': '2025-05-22T15:20:06.847233+00:00',\n",
            " 'trace_id': 'trace_04d70b6ce85b477ea557338afc31422b'}\n",
            "Span Started: span_ac8e98bf8152400a84988aaa\n",
            "Spane Details:\n",
            "{'ended_at': None,\n",
            " 'error': None,\n",
            " 'id': 'span_ac8e98bf8152400a84988aaa',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': 'span_6f46daf9fb5a4433b51b336b',\n",
            " 'span_data': {'input': None,\n",
            "               'model': 'gemini-2.0-flash',\n",
            "               'model_config': {'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/',\n",
            "                                'extra_body': None,\n",
            "                                'extra_headers': None,\n",
            "                                'extra_query': None,\n",
            "                                'frequency_penalty': None,\n",
            "                                'include_usage': None,\n",
            "                                'max_tokens': None,\n",
            "                                'metadata': None,\n",
            "                                'parallel_tool_calls': None,\n",
            "                                'presence_penalty': None,\n",
            "                                'reasoning': None,\n",
            "                                'store': None,\n",
            "                                'temperature': None,\n",
            "                                'tool_choice': None,\n",
            "                                'top_p': None,\n",
            "                                'truncation': None},\n",
            "               'output': None,\n",
            "               'type': 'generation',\n",
            "               'usage': None},\n",
            " 'started_at': '2025-05-22T15:20:06.847739+00:00',\n",
            " 'trace_id': 'trace_04d70b6ce85b477ea557338afc31422b'}\n",
            "Span Ended: span_ac8e98bf8152400a84988aaa\n",
            "Spane Details:\n",
            "{'ended_at': '2025-05-22T15:20:09.012511+00:00',\n",
            " 'error': None,\n",
            " 'id': 'span_ac8e98bf8152400a84988aaa',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': 'span_6f46daf9fb5a4433b51b336b',\n",
            " 'span_data': {'input': [{'content': 'Tell a joke to the user',\n",
            "                          'role': 'system'},\n",
            "                         {'content': \"Rate this joke out of 10 Why don't \"\n",
            "                                     'scientists trust atoms?\\n'\n",
            "                                     '\\n'\n",
            "                                     'Because they make up everything!\\n',\n",
            "                          'role': 'user'}],\n",
            "               'model': 'gemini-2.0-flash',\n",
            "               'model_config': {'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/',\n",
            "                                'extra_body': None,\n",
            "                                'extra_headers': None,\n",
            "                                'extra_query': None,\n",
            "                                'frequency_penalty': None,\n",
            "                                'include_usage': None,\n",
            "                                'max_tokens': None,\n",
            "                                'metadata': None,\n",
            "                                'parallel_tool_calls': None,\n",
            "                                'presence_penalty': None,\n",
            "                                'reasoning': None,\n",
            "                                'store': None,\n",
            "                                'temperature': None,\n",
            "                                'tool_choice': None,\n",
            "                                'top_p': None,\n",
            "                                'truncation': None},\n",
            "               'output': [{'annotations': None,\n",
            "                           'audio': None,\n",
            "                           'content': \"Okay, here's my rating and why:\\n\"\n",
            "                                      '\\n'\n",
            "                                      '**Rating: 7/10**\\n'\n",
            "                                      '\\n'\n",
            "                                      '**Why:**\\n'\n",
            "                                      '\\n'\n",
            "                                      \"*   **Classic and Simple:** It's a \"\n",
            "                                      'well-known pun-based joke, which makes '\n",
            "                                      'it accessible and easy to understand. '\n",
            "                                      'Puns are generally appreciated.\\n'\n",
            "                                      '\\n'\n",
            "                                      '*   **Relatable to Science:** The '\n",
            "                                      'subject matter is science-related, '\n",
            "                                      'which gives it a bit of intellectual '\n",
            "                                      \"flair, even if it's lighthearted.\\n\"\n",
            "                                      '\\n'\n",
            "                                      '*   **Good Wordplay:** The humor comes '\n",
            "                                      'from the double meaning of \"make up\" '\n",
            "                                      '(to invent a story vs. to constitute '\n",
            "                                      'something), which is a key element of a '\n",
            "                                      'good pun.\\n'\n",
            "                                      '\\n'\n",
            "                                      \"*   **Slightly Overused:** Because it's \"\n",
            "                                      'so well-known, it might not elicit a '\n",
            "                                      'huge laugh from everyone who has heard '\n",
            "                                      'it before. Originality sometimes counts '\n",
            "                                      'for bonus points.\\n'\n",
            "                                      '\\n'\n",
            "                                      \"So, overall, it's a solid joke with a \"\n",
            "                                      'clever pun, but its familiarity keeps '\n",
            "                                      'it from being a perfect 10.\\n'\n",
            "                                      '\\n'\n",
            "                                      'Do you want to hear another joke?\\n',\n",
            "                           'function_call': None,\n",
            "                           'refusal': None,\n",
            "                           'role': 'assistant',\n",
            "                           'tool_calls': None}],\n",
            "               'type': 'generation',\n",
            "               'usage': {'input_tokens': 30, 'output_tokens': 213}},\n",
            " 'started_at': '2025-05-22T15:20:06.847739+00:00',\n",
            " 'trace_id': 'trace_04d70b6ce85b477ea557338afc31422b'}\n",
            "Span Ended: span_6f46daf9fb5a4433b51b336b\n",
            "Spane Details:\n",
            "{'ended_at': '2025-05-22T15:20:09.014022+00:00',\n",
            " 'error': None,\n",
            " 'id': 'span_6f46daf9fb5a4433b51b336b',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': None,\n",
            " 'span_data': {'handoffs': [],\n",
            "               'name': 'Joke Teller Agent',\n",
            "               'output_type': 'str',\n",
            "               'tools': [],\n",
            "               'type': 'agent'},\n",
            " 'started_at': '2025-05-22T15:20:06.847233+00:00',\n",
            " 'trace_id': 'trace_04d70b6ce85b477ea557338afc31422b'}\n",
            "Why don't scientists trust atoms?\n",
            "\n",
            "Because they make up everything!\n",
            "\n",
            "Okay, here's my rating and why:\n",
            "\n",
            "**Rating: 7/10**\n",
            "\n",
            "**Why:**\n",
            "\n",
            "*   **Classic and Simple:** It's a well-known pun-based joke, which makes it accessible and easy to understand. Puns are generally appreciated.\n",
            "\n",
            "*   **Relatable to Science:** The subject matter is science-related, which gives it a bit of intellectual flair, even if it's lighthearted.\n",
            "\n",
            "*   **Good Wordplay:** The humor comes from the double meaning of \"make up\" (to invent a story vs. to constitute something), which is a key element of a good pun.\n",
            "\n",
            "*   **Slightly Overused:** Because it's so well-known, it might not elicit a huge laugh from everyone who has heard it before. Originality sometimes counts for bonus points.\n",
            "\n",
            "So, overall, it's a solid joke with a clever pun, but its familiarity keeps it from being a perfect 10.\n",
            "\n",
            "Do you want to hear another joke?\n",
            "\n",
            "Trace Ended :{'object': 'trace', 'id': 'trace_04d70b6ce85b477ea557338afc31422b', 'workflow_name': 'Joker Tracing', 'group_id': None, 'metadata': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To Integrate A 3rd Party Interface To View Tracing Like AgentOPS"
      ],
      "metadata": {
        "id": "3xG19LwJqXKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq agentops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkWzfsp8kEYJ",
        "outputId": "d3d7fafd-f1b8-40d8-d686-dcfa48e31504"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/198.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m194.6/198.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.3/198.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "AGENTOPS_API_KEY = userdata.get(\"AGENTOPS_API_KEY\")"
      ],
      "metadata": {
        "id": "UzMsZAhkq3b5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import agentops\n",
        "agentops.init(AGENTOPS_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2sSKZfarLvp",
        "outputId": "f53a5510-26ea-4c78-93c0-f4cc8a015430"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🖇 AgentOps: \u001b[34mSession Replay: https://app.agentops.ai/sessions?trace_id=65e480f46609ead333b085792908cb70\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<agentops.legacy.Session at 0x7a525194bf50>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def main_2():\n",
        "   agent = Agent(\n",
        "    name = \"Joke Teller Agent\",\n",
        "    instructions=\"Tell a joke to the user\",\n",
        "    model = \"gemini-2.0-flash\"\n",
        ")\n",
        "\n",
        "   with trace(\"Joker Tracing\"):\n",
        "    result_1 = await Runner.run(agent, \"Tell me a joke\")\n",
        "    result_2 = await Runner.run(agent, f\"Rate this joke out of 10 {result_1.final_output}\")\n",
        "    print(result_1.final_output)\n",
        "    print(result_2.final_output)\n",
        "\n",
        "asyncio.run(main_2())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ_6AHNfrWcO",
        "outputId": "17370419-44e0-4728-d98d-62cafc600f90"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why don't scientists trust atoms?\n",
            "\n",
            "Because they make up everything!\n",
            "\n",
            "I'd rate that joke a solid 7/10. \n",
            "\n",
            "Here's why:\n",
            "\n",
            "*   **It's a classic:** The pun is well-known and predictable, but that also makes it accessible and easy to understand.\n",
            "*   **It's clean:** No offensive content or complicated setup.\n",
            "*   **It's clever (in a simple way):** The wordplay on \"make up\" is the key to the humor.\n",
            "*   **It's not laugh-out-loud funny:** While it's a good joke, it's unlikely to cause strong laughter. More of a chuckle or a smile.\n",
            "\n",
            "Overall, it's a reliable, pun-based joke that's good for a quick, lighthearted moment.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0g3e5Mp3r0ZX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}